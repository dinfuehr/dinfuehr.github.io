<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dominik&#39;s Blog</title>
    <link>https://dinfuehr.github.io/index.xml</link>
    <description>Recent content on Dominik&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Apr 2017 20:33:37 +0200</lastBuildDate>
    <atom:link href="https://dinfuehr.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Encoding of immediate values on AArch64</title>
      <link>https://dinfuehr.github.io/blog/encoding-of-immediate-values-on-aarch64/</link>
      <pubDate>Thu, 20 Apr 2017 20:33:37 +0200</pubDate>
      
      <guid>https://dinfuehr.github.io/blog/encoding-of-immediate-values-on-aarch64/</guid>
      <description>

&lt;p&gt;AArch64 is an ISA with a fixed instruction width of 32-bit.
This obviously means there is not enough space to store a 64-bit immediate in a single instruction.
Before working with AArch64 I was only familiar with x86 where this is a bit easier since instructions can have variable-width.
A 64-bit immediate on x86-64 is really just the sequence of bytes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mov rax, 0x1122334455667788
# encoded as: 0x48, 0xB8, 0x88, 0x77, 0x66, 0x55, 0x44, 0x33, 0x22, 0x11
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A fixed-width ISA like ARM has to treat immediates differently.
Assigning the same value to the register &lt;code&gt;x0&lt;/code&gt; takes four instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;movz x0, 0x7788
movk x0, 0x5566, lsl 16
movk x0, 0x3344, lsl 32
movk x0, 0x1122, lsl 48
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;move-wide-immediates&#34;&gt;Move wide immediates&lt;/h1&gt;

&lt;p&gt;The move instructions (&lt;code&gt;movz&lt;/code&gt;, &lt;code&gt;movn&lt;/code&gt; and &lt;code&gt;movk&lt;/code&gt;) have space for a 16-bit unsigned immediate that can be shifted by either 0, 16, 32 or 48 bits (2 bits for the shift).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;movz&lt;/code&gt; assigns the given 16-bit value to the position given by the shift operand and &lt;code&gt;z&lt;/code&gt;eroes all other bits.
&lt;code&gt;movk&lt;/code&gt; does the same but &lt;code&gt;k&lt;/code&gt;eeps the value of the other bits instead of zeroing them.
So in the worst case a 64-bit immediate needs 4 instructions.
But many common immediates can be encoded in less:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# x0 = 0x10000
movz x0, 0x1, lsl 16

# x0 = 0x10001
movz x0, 0x1
movk x0, 0x1, lsl 16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is only necessary to initialize the 16-bit parts of the 64-bit register that are non-zero.
Now that we have seen this, how can we encode -1?
All bits are 1 in this case, so with only &lt;code&gt;movz&lt;/code&gt; and &lt;code&gt;movk&lt;/code&gt; we would have to use 4 instructions again.&lt;/p&gt;

&lt;p&gt;For such numbers AArch64 features the &lt;code&gt;movn&lt;/code&gt; instruction that assigns the expression &lt;code&gt;~(imm16 &amp;lt;&amp;lt; shift)&lt;/code&gt; to the register.
-1 can so be encoded in one single instruction: &lt;code&gt;movn x0, 0&lt;/code&gt;.
&lt;code&gt;movn&lt;/code&gt; can also be combined with &lt;code&gt;movk&lt;/code&gt;, use it to set parts of the number that are not all ones.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/v8/v8/blob/master/src/arm64/macro-assembler-arm64.cc#L164&#34;&gt;v8&lt;/a&gt; for example really determines whether it is more beneficial (this means less instructions) to encode an immediate via &lt;code&gt;movn&lt;/code&gt; or &lt;code&gt;movz&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;add-sub-immediates&#34;&gt;Add/Sub Immediates&lt;/h1&gt;

&lt;p&gt;In addition to immediates in move instructions, some instructions like &lt;code&gt;add&lt;/code&gt; or &lt;code&gt;sub&lt;/code&gt; also accept an immediate as operand.
This allows to encode some numbers directly into the instruction, instead of using a temporary register.
All instructions of the add/sub immediate instruction class allow a 12-bit unsigned immediate that can optionally be shifted by 12 bits (1 bit for the shift).
If you want to use these instructions with an immediate that can&amp;rsquo;t be encoded in this format, you have no choice but to use a temporary register and possibly multiple instructions for initializing this register.
Although negative numbers e.g. -1 (which is all ones) cannot be encoded with an &lt;code&gt;add&lt;/code&gt; instruction, the instruction &lt;code&gt;sub&lt;/code&gt; can be used to subtract 1: &lt;code&gt;sub x0, x0, 1&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;logical-immediates&#34;&gt;Logical Immediates&lt;/h1&gt;

&lt;p&gt;There is another instruction class that allows immediates as an operand: logical immediate. This instruction class is used for &lt;code&gt;and&lt;/code&gt; (bitwise and), &lt;code&gt;orr&lt;/code&gt; (bitwise or), &lt;code&gt;eor&lt;/code&gt; (bitwise exclusive or) and &lt;code&gt;ands&lt;/code&gt; (bitwise and and set flags).
This instruction class is the most complicated and non-intuitive (at least for me) and the reason I started to write this blog post.
Let&amp;rsquo;s look into the definition from the ARM Reference Manual:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The logical immediate instructions accept a bitmask immediate bimm32 or bimm64.
Such an immediate consists EITHER of a single consecutive sequence with at least one non-zero bit, and at least one zero bit, within an element of 2, 4, 8, 16, 32 or 64 bits;
the element then being replicated across the register width, or the bitwise inverse of such a value.
The immediate values of all-zero and all-ones may not be encoded as a bitmask immediate, so an assembler must either generate an error for a logical instruction with such an immediate,
or a programmer-friendly assembler may transform it into some other instruction which achieves the intended result.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That&amp;rsquo;s quite a lot of information in such a short paragraph.
I will try to describe this format in my own words:
Logical immediate instructions have 13-bits for encoding the immediate, it consists of three fields &lt;code&gt;N&lt;/code&gt; (1 bit), &lt;code&gt;immr&lt;/code&gt; (6 bits) and &lt;code&gt;imms&lt;/code&gt; (6 bits).
This format does not allow to encode 0 or ~0 (all ones) as an immediate.
Although this sounds problematic at first, this isn&amp;rsquo;t actually a restriction: this format is only used for instructions such as bitwise &lt;code&gt;and&lt;/code&gt; and &lt;code&gt;orr&lt;/code&gt; where these constants are not really useful (e.g. &lt;code&gt;x0 | 0&lt;/code&gt; can be optimized to &lt;code&gt;x0&lt;/code&gt; while &lt;code&gt;x0 | ~0&lt;/code&gt; can be optimized to &lt;code&gt;~0&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The bit pattern of the immediate consists of identical sub-patterns with 2-, 4-, 8-, 16-, 32- or 64-bits length.
Both the sub-pattern size and value is stored in the &lt;code&gt;N&lt;/code&gt; and &lt;code&gt;imms&lt;/code&gt; fields.
The bit pattern needs to be a consecutive sequence of (at least one) zeroes, followed by a consecutive sequence of (at least one) ones (the regex for that pattern would be &lt;code&gt;0+1+&lt;/code&gt;).
To generate the bit pattern, the format really just stores the number of consecutive ones in the element and the size of the element.&lt;/p&gt;

&lt;p&gt;The so specified element value can be right-rotated up to element size minus 1 to move the start of the sequence of ones to any other point in the element.
The number of rotations is stored in &lt;code&gt;immr&lt;/code&gt; which has 6 bits, so it allows up to 63 rotations in the case of an element size of 64 bits.
An element size of 2 only allows 0 or 1 rotations, in this case only the least significant bit is considered, the upper 5 bits of &lt;code&gt;immr&lt;/code&gt; are simply ignored.&lt;/p&gt;

&lt;p&gt;The element gets replicated until it reaches 32- or 64-bits.
13-bits could store 8192 different values, but since e.g. the rotation is not always used to its full potential with smaller element sizes it actually allows less different values but probably a more useful set of bit patterns.&lt;/p&gt;

&lt;p&gt;Since &lt;code&gt;immr&lt;/code&gt; is actually quite boring (just stores the number of rotations), let&amp;rsquo;s look into how &lt;code&gt;N&lt;/code&gt; and &lt;code&gt;imms&lt;/code&gt; can store both the element size and the number of consecutive ones at the same time:&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;N&lt;/td&gt;
    &lt;td colspan=&#34;6&#34;&gt;imms&lt;/td&gt;
    &lt;td&gt;element size&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;2 bits&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;4 bits&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;8 bits&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;16 bits&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;32 bits&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;x&lt;/td&gt;
    &lt;td&gt;64 bits&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;The upper bits specify the element size, while the lower bits marked with &lt;code&gt;x&lt;/code&gt; are used to store the consecutive sequence of ones.
0 means there is one 1 in the bit pattern, 1 means there are two 1&amp;rsquo;s and so on.
At the same time it is not allowed to set all &lt;code&gt;x&lt;/code&gt; to 1, since this would allow to create all ones
(Remember: The format doesn&amp;rsquo;t allow 0 or all ones to be encoded).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see some examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0|111100&lt;/code&gt; represents element &lt;code&gt;01&lt;/code&gt; (2 bits element size, one 1)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;0|110101&lt;/code&gt; represents element &lt;code&gt;00111111&lt;/code&gt; (8 bits element size, six 1&amp;rsquo;s)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There was an interesting &lt;a href=&#34;http://stackoverflow.com/a/33265035/727454&#34;&gt;answer on Stack Overflow&lt;/a&gt; that enumerates all 5334 possible 64-bit immediates with this encoding.
I ported this [code to Ruby]() and dumped the fields &lt;code&gt;n&lt;/code&gt;, &lt;code&gt;immr&lt;/code&gt; and &lt;code&gt;imms&lt;/code&gt; for all values.
See here for the [full output]() of the script.
I verified the output by comparing all values to the output of the AArch64 assembler.
Scrolling over all values, element sizes, rotations etc. should give you a quick overview of what numbers can be encoded with this representation.&lt;/p&gt;

&lt;p&gt;For some source code examples, see e.g. LLVM, which also handles &lt;a href=&#34;https://github.com/llvm-mirror/llvm/blob/master/lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h#L213&#34;&gt;encoding&lt;/a&gt; and &lt;a href=&#34;https://github.com/llvm-mirror/llvm/blob/master/lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h#L292&#34;&gt;decoding&lt;/a&gt; of logical immediates.&lt;/p&gt;

&lt;h1 id=&#34;other-immediates&#34;&gt;Other immediates&lt;/h1&gt;

&lt;p&gt;There are even more instruction classes that accept immediates as operands
(There is even one with floating-point).
But IMHO they are not as complicated as the logical immediate class.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>about</title>
      <link>https://dinfuehr.github.io/about/</link>
      <pubDate>Wed, 04 Jan 2017 08:47:14 +0100</pubDate>
      
      <guid>https://dinfuehr.github.io/about/</guid>
      <description>&lt;p&gt;Hi, I am Dominik Inf√ºhr.
I write about programming, compilers and VMs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dora: Implementing a JIT-compiler with Rust</title>
      <link>https://dinfuehr.github.io/blog/dora-implementing-a-jit-compiler-with-rust/</link>
      <pubDate>Wed, 04 Jan 2017 08:34:34 +0100</pubDate>
      
      <guid>https://dinfuehr.github.io/blog/dora-implementing-a-jit-compiler-with-rust/</guid>
      <description>

&lt;p&gt;I am writing &lt;a href=&#34;https://github.com/dinfuehr/dora&#34;&gt;Dora&lt;/a&gt;, a simple &lt;a href=&#34;https://en.wikipedia.org/wiki/Just-in-time_compilation&#34;&gt;JIT-compiler&lt;/a&gt; with Rust.
Dora is both the name of the custom programming language and of the JIT-compiler.
After some time working on it, I want to write about the experiences I made.&lt;/p&gt;

&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;The architecture is pretty simple: &lt;code&gt;dora hello.dora&lt;/code&gt; parses the given input file into an &lt;a href=&#34;https://en.wikipedia.org/wiki/Abstract_syntax_tree&#34;&gt;Abstract Syntax Tree (AST)&lt;/a&gt;. After parsing the whole AST is semantically checked, if this succeeds execution starts with the &lt;code&gt;main&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;To execute &lt;code&gt;main&lt;/code&gt;, machine-code is generated for that function by the baseline compiler by &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/src/baseline/codegen.rs&#34;&gt;traversing&lt;/a&gt; the AST nodes of the function.
The function is traversed twice, first to generate information (mostly about the stack frame), the second traversal then generates the machine code.&lt;/p&gt;

&lt;p&gt;The baseline compiler is a method-based compiler and not a &lt;a href=&#34;https://en.wikipedia.org/wiki/Tracing_just-in-time_compilation&#34;&gt;tracing JIT&lt;/a&gt; like for example &lt;a href=&#34;http://luajit.org/&#34;&gt;LuaJIT&lt;/a&gt;.
The purpose of the baseline compiler in Dora is to generate code as fast as possible, not to generate the most efficient code.
The sooner it finishes code generation, the sooner execution can start.&lt;/p&gt;

&lt;p&gt;Many VMs like the JVM pair the baseline compiler with one or more optimizing compilers that compile functions to more efficient machine-code if it detects a function to be hot.
The optimizing compiler needs longer to compile a given function, but generates more optimized machine-code.
This is acceptable since not all code gets compiled by the optimizing compiler but only hot code/functions.
Dora doesn&amp;rsquo;t have an optimizing compiler at the moment.&lt;/p&gt;

&lt;h3 id=&#34;compilation&#34;&gt;Compilation&lt;/h3&gt;

&lt;p&gt;The baseline compiler uses the &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/src/masm/mod.rs#L28&#34;&gt;MacroAssembler&lt;/a&gt; to generate machine code.
All differences between different Instruction Set Architectures (ISAs) are handled by the MacroAssembler.
Dora can generate machine-code for x86_64 and since about two weeks also for AArch64.
Adding other platforms should be possible without touching the baseline compiler.&lt;/p&gt;

&lt;p&gt;Implementing the second ISA certainly helped making the architecture cleaner and unveiled two bugs I didn&amp;rsquo;t notice on x86_64.
It was also pretty interesting to implement instruction encoding, both for &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/src/cpu/x64/asm.rs&#34;&gt;x86_64&lt;/a&gt; and &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/src/cpu/arm64/asm.rs&#34;&gt;AArch64&lt;/a&gt;.
I didn&amp;rsquo;t implement instruction decoding myself, for this purpose I used the &lt;a href=&#34;http://www.capstone-engine.org/&#34;&gt;capstone&lt;/a&gt; library.
The generated machine-code can be emitted with &lt;code&gt;dora --emit-asm=all hello-world.dora&lt;/code&gt;.
A nice feature of the MacroAssembler is that comments can be added to the generated instructions.
When disassembling the comments are printed along the disassembled machine instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fn main() 0x7f33bab6d010
  0x7f33bab6d010: pushq		%rbp
  0x7f33bab6d011: movq		%rsp, %rbp
  0x7f33bab6d014: subq		$0x10, %rsp
		  ; prolog end


		  ; load string
  0x7f33bab6d018: movq		-0x17(%rip), %rax
  0x7f33bab6d01f: movq		%rax, -8(%rbp)
  0x7f33bab6d023: movq		-8(%rbp), %rdi
		  ; call direct println(Str)
  0x7f33bab6d027: movq		-0x2e(%rip), %rax
  0x7f33bab6d02e: callq		*%rax

		  ; epilog
  0x7f33bab6d030: addq		$0x10, %rsp
  0x7f33bab6d034: popq		%rbp
  0x7f33bab6d035: retq
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There already exists a &lt;a href=&#34;https://github.com/ebfe/rust-capstone&#34;&gt;Rust wrapper&lt;/a&gt; for the capstone libary.
Although the README states that the bindings are incomplete, the wrapper supported all the features I need.&lt;/p&gt;

&lt;h3 id=&#34;the-dora-programming-language&#34;&gt;The Dora programming language&lt;/h3&gt;

&lt;p&gt;Here is a simple Hello world program:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fun main() {
    println(&amp;quot;Hello World&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dora is a custom-language with similarities to languages like Java, Kotlin and Rust (only syntactical).
Most important: Dora is statically-typed and garbage collected.
Dora is missing a lot of features, I planned to add more but writing a JIT is more than enough work.
Instead of adding more syntactic sugar, I preferred to implement features that are more interesting to implement in the JIT.&lt;/p&gt;

&lt;p&gt;So Dora has no floating point numbers, the only array it knows is &lt;code&gt;IntArray&lt;/code&gt;.
A class with the name &lt;code&gt;IntArray&lt;/code&gt; almost reveals that there no generics, interfaces or traits yet.
The only primitive datatypes Dora supports right now are &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt; and pointer-sized class references.&lt;/p&gt;

&lt;p&gt;Why didn&amp;rsquo;t I use an already existing language? I originally planned designing my own language.
But even if I had used an already existing intermediate representation, bytecode or language, I certainly couldn&amp;rsquo;t have implemented it fully either.&lt;/p&gt;

&lt;h3 id=&#34;supported-features&#34;&gt;Supported Features&lt;/h3&gt;

&lt;p&gt;So what are the features Dora actually supports?&lt;/p&gt;

&lt;p&gt;Dora compiles functions on-demand, functions are not compiled if not executed.
I want to describe this mechanism in more detail in a later blog post.&lt;/p&gt;

&lt;p&gt;Exceptions can be thrown with &lt;code&gt;throw&lt;/code&gt;, while &lt;code&gt;do&lt;/code&gt;, &lt;code&gt;catch&lt;/code&gt; and &lt;code&gt;finally&lt;/code&gt; can be used to catch exceptions.
Doras exception handling is similar to &lt;a href=&#34;https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/ErrorHandling.html&#34;&gt;Swift&lt;/a&gt;, all functions that can throw exceptions need to be marked with &lt;code&gt;throws&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fun foo() throws { /* ... */ }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Functions that can throw need to be invoked like &lt;code&gt;try foo()&lt;/code&gt; or &lt;code&gt;try obj.bar()&lt;/code&gt;, where &lt;code&gt;try&lt;/code&gt; is just syntactic sugar that signals a potentially throwing invocation.
I like this syntax because it makes it obvious in the caller that an exception could occur.&lt;/p&gt;

&lt;p&gt;For runtime errors like failed assertions, the program is halted and the current stack trace is printed.
Although exceptions and stack traces sound quite unspectacular, I was quite happy when this worked for the first time.&lt;/p&gt;

&lt;p&gt;Dora even supports classes and inheritance.
It has &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/tests/pctor1.dora&#34;&gt;primary&lt;/a&gt; and &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/tests/ctor3.dora&#34;&gt;secondary&lt;/a&gt; constructors like &lt;a href=&#34;https://kotlinlang.org/docs/reference/classes.html&#34;&gt;Kotlin&lt;/a&gt;.
The keyword &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/tests/is1.dora&#34;&gt;&lt;code&gt;is&lt;/code&gt;&lt;/a&gt; is similar to Javas &lt;code&gt;instanceof&lt;/code&gt;, while &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/tests/as1.dora&#34;&gt;&lt;code&gt;as&lt;/code&gt;&lt;/a&gt; is used for the checked cast (in Java you would write &lt;code&gt;(SomeClass) obj&lt;/code&gt; for that).
I implemented this check as described in this great &lt;a href=&#34;https://www.researchgate.net/publication/221552851_Fast_subtype_checking_in_the_HotSpot_JVM&#34;&gt;paper&lt;/a&gt; from Cliff Click and John Rose.
Unfortunately I haven&amp;rsquo;t benchmarked my implementation of the &lt;em&gt;fast subtype check&lt;/em&gt; yet.
My implementation is a bit easier since Dora doesn&amp;rsquo;t have interfaces or dynamically loaded classes.&lt;/p&gt;

&lt;h3 id=&#34;garbage-collection&#34;&gt;Garbage Collection&lt;/h3&gt;

&lt;p&gt;Dora has an exact, tracing &lt;a href=&#34;https://en.wikipedia.org/wiki/Tracing_garbage_collection&#34;&gt;Garbage Collector&lt;/a&gt;.
The GC&amp;rsquo;s implementation is pretty simple: it uses a mark &amp;amp; sweep algorithm.
Each object stores a flag that the GC needs for bookkeeping.
The flag determines if the object is marked or unmarked respectively reachable or unreachable.
We only need this flag while collecting garbage.&lt;/p&gt;

&lt;p&gt;Mark &amp;amp; sweep is separated into two phases:
&lt;em&gt;Marking&lt;/em&gt; is the first phase that recursively marks all reachable objects, while &lt;em&gt;Sweeping&lt;/em&gt; &lt;code&gt;free&lt;/code&gt;s all unmarked (=unreachable) objects in the second phase.
If you don&amp;rsquo;t know how Mark &amp;amp; Sweep works, there is a nice GIF on &lt;a href=&#34;https://en.wikipedia.org/wiki/Tracing_garbage_collection#Na.C3.AFve_mark-and-sweep&#34;&gt;Wikipedia&lt;/a&gt; that shows how it works.
Marking one object means setting the mark-flag and recursively traversing through all subobjects and marking them too.
A nice property of the marking phase is that cycles in the object graph are no problem.
On the other hand you need to be careful to avoid stack overflows when you have deeply nested object graphs, so you probably shouldn&amp;rsquo;t implement marking through an recursive function call.
That&amp;rsquo;s the reason I just add the objects into a &lt;a href=&#34;https://doc.rust-lang.org/std/vec/struct.Vec.html&#34;&gt;Vec&lt;/a&gt; instead of using the stack.
When sweeping, the garbage collector simply runs through all allocated objects and frees unmarked objects.&lt;/p&gt;

&lt;p&gt;The GC really just uses libc&amp;rsquo;s &lt;code&gt;malloc&lt;/code&gt; for allocating objects and &lt;code&gt;free&lt;/code&gt; while &lt;em&gt;Sweeping&lt;/em&gt;.
All allocated objects are connected in a single linked list.
For this to work, each object has an additional storage for the pointer to the next allocated object in the object header.
While this increases the size of every object, we don&amp;rsquo;t need to keep track of all objects in some external data structure.
Since all collected objects are part of this linked list, the &lt;em&gt;Sweeping&lt;/em&gt; phase can run through all objects and free those that are not marked.
When the collector frees a object, it also gets removed from the linked list.&lt;/p&gt;

&lt;p&gt;For exact GC to work, it is also essential to determine the root set.
The root set is the initial set of objects that gets marked in the marking phase.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn collect_garbage() {
    for root in root_set {
        mark(root);
    }

    sweep();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The set usually consists of global variables, static fields and/or local variables
(but keep in mind that Dora doesn&amp;rsquo;t have global variables or static fields right now).
Within Dora string literals are also part of the root set, otherwise the GC would just free a String object that is still referenced in a compiled function.&lt;/p&gt;

&lt;p&gt;The toughest part while gathering the root set is retrieving local variables.
For this we need working stack unwinding, Dora needs to examine the active functions on the stack.
Although we then know all local variables in these functions, there is one more complication:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-dora&#34;&gt;fun foo() {
    let x = A(); // create object of class A
    bar1(); // GC Point 1

    let y = A(); // create another object of class A
    bar2(); // GC Point 2

    // use x and y
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For determining local variables we also need to know where in a function we currently are.
The Dora function &lt;code&gt;foo&lt;/code&gt; has two local variables, but when invoking &lt;code&gt;bar1&lt;/code&gt; only &lt;code&gt;x&lt;/code&gt; is initialized.
At this point there is already space reservered for &lt;code&gt;y&lt;/code&gt; but the memory is still uninitialized and contains some random value.
&lt;code&gt;y&lt;/code&gt; shouldn&amp;rsquo;t be part of the root set at that point.
When invoking &lt;code&gt;bar2&lt;/code&gt; both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are initialized and therefore belong to the root set.&lt;/p&gt;

&lt;p&gt;The baseline compiler keeps track of initialized local variables and emits so called GC points for each function invocation.
The GC point stores which local variables are initialized.
Now there is enough information to collect all local variables from the stack.
To be more precise Dora not only keeps track of local variables but also of temporary values, fortunately temporary values can just be treated like local variables.&lt;/p&gt;

&lt;p&gt;To test garbage collection, I added a command line flag &lt;code&gt;--gc-stress&lt;/code&gt; that forces garbage collection at every allocation.
There is also a function &lt;code&gt;forceCollect&lt;/code&gt; that immediately forces garbage collection, that can be called from Dora code.&lt;/p&gt;

&lt;h3 id=&#34;benchmark&#34;&gt;Benchmark&lt;/h3&gt;

&lt;p&gt;I can&amp;rsquo;t stop without showing some benchmark results.
There are two microbenchmarks Dora could run from the &lt;a href=&#34;http://benchmarksgame.alioth.debian.org/&#34;&gt;Language Benchmarks Game&lt;/a&gt;: &lt;a href=&#34;https://github.com/dinfuehr/dora/tree/master/bench/fannkuchredux&#34;&gt;fannkuch-redux&lt;/a&gt; and &lt;a href=&#34;https://github.com/dinfuehr/dora/tree/master/bench/binarytrees&#34;&gt;binarytrees&lt;/a&gt;.
I chose the fastest single-threaded Java implementation (dora does not support multi-threading yet) of these benchmarks and translated them to Dora.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dinfuehr.github.io/images/dora-bench-game.png&#34; alt=&#34;Benchmark results&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For &lt;code&gt;fannkuch-redux&lt;/code&gt; Dora is only 3.5 times (40s to 138s) slower than the Java equivalent running on OpenJDK (version 1.8.0_112), the benchmark results for &lt;code&gt;binarytrees&lt;/code&gt; are worse: Dora is 14x slower (55s instead of 4s).
This is easily explained: &lt;code&gt;binarytrees&lt;/code&gt; stresses the GC and the current implementation isn&amp;rsquo;t really the most efficient.
We will later look into this benchmark in more detail.&lt;/p&gt;

&lt;p&gt;Nevertheless I am satisfied with these numbers.
Neither did I cheat nor am I expecting these numbers to get worse when adding more features.&lt;/p&gt;

&lt;p&gt;It should be clear but just to make sure: Please don&amp;rsquo;t draw any conclusions on Rust&amp;rsquo;s performance from these benchmarks.
All time is spent in the generated machine-code, Dora is at fault not Rust.&lt;/p&gt;

&lt;h3 id=&#34;binarytrees&#34;&gt;binarytrees&lt;/h3&gt;

&lt;p&gt;We can look deeper into the &lt;code&gt;binarytrees&lt;/code&gt; benchmark and run the program with &lt;a href=&#34;https://perf.wiki.kernel.org/index.php/Main_Page&#34;&gt;perf&lt;/a&gt;.
perf can record stacktraces using sampling.
Thanks to &lt;a href=&#34;http://www.brendangregg.com/&#34;&gt;Brendan Gregg&lt;/a&gt; we can create &lt;a href=&#34;https://github.com/brendangregg/FlameGraph&#34;&gt;flame graphs&lt;/a&gt; as interactive SVGs from the collected stacktraces, which is pretty cool:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://dinfuehr.github.io/images/perf-binarytrees.svg&#34;&gt;&lt;img src=&#34;https://dinfuehr.github.io/images/perf-binarytrees.svg&#34; alt=&#34;binarytrees flame graph&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s also pretty nice is that perf shows both user and kernel stack traces.
We can observe that the memory allocator uses another thread, since there is a pretty wide column next to function &lt;code&gt;dora::main&lt;/code&gt;, the &lt;code&gt;main&lt;/code&gt; function in &lt;a href=&#34;https://github.com/dinfuehr/dora/tree/master/bench/binarytrees/binarytrees.dora&#34;&gt;binarytrees.dora&lt;/a&gt;.
&lt;code&gt;perf&lt;/code&gt; even emits the function names for the jitted functions, which was actually pretty easy to achieve.
All you need to do is to &lt;a href=&#34;https://github.com/dinfuehr/dora/blob/master/src/os/perf.rs&#34;&gt;create&lt;/a&gt; a file &lt;code&gt;/tmp/perf-&amp;lt;pid&amp;gt;.map&lt;/code&gt; that consists of lines with this format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;code address start&amp;gt; &amp;lt;length&amp;gt; &amp;lt;function name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dora just needs to emit such lines for every jitted function.
Dora also supports emitting garbage collection stats with &lt;code&gt;--gc-stats&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GC stats:
	collect duration: 17715 ms
	607475118 allocations
	75 collections
	29158805890 bytes allocated
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We see that Dora spends 17 seconds alone for collecting garbage, this benchmarks makes over 600 million allocations to allocate a total of about 27GB memory.
At first I also wanted to benchmark allocation duration but this was way too expensive.
Just by removing those &lt;code&gt;time::precise_time_ns&lt;/code&gt; invocations reduced run-time from 110s to 55s.&lt;/p&gt;

&lt;h3 id=&#34;using-rust&#34;&gt;Using Rust&lt;/h3&gt;

&lt;p&gt;A few words on using Rust: I started the project to try out Rust on a non-trivial project.
I knew some Rust but hadn&amp;rsquo;t used it on a project before.
Both &lt;code&gt;cargo&lt;/code&gt; and &lt;code&gt;rustup&lt;/code&gt; are great tools.
They also work on my Odroid C2 where I implemented AArch64 support.
Cross-compiling became pretty easy, although I just used it for making sure Dora still builds on AArch64
(I never bothered to try to get it to link).
Cross-building is as simple as &lt;code&gt;cargo build --target=aarch64-unknown-linux-gnu&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;What was especially hard for me to get used to was exclusive mutability, not really borrowing or ownership.
I am perfectly aware that this feature is the reason I don&amp;rsquo;t have to worry about iterator invalidation or data races in safe rust code but still it takes some time getting used to.
The good thing about that though, it forces you to think about organizing your data structures more thoroughly.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Implementing both a programming language and JIT is a LOT of work.
Nevertheless working on it was both fun and educational and there is still so much stuff that would be cool to implement or to improve.
The source is on &lt;a href=&#34;https://github.com/dinfuehr/dora&#34;&gt;Github&lt;/a&gt;, contributions are welcome.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>